ğŸ§¬ Machine Learning Classification of Structural Protein Sequences for Drug Discovery

Authors:
Paul London, Ernest Bonat, Ph.D.

ğŸ“˜ Overview

This repository accompanies the project â€œMachine Learning Classification of Structural Protein Sequences for Drug Discovery.â€
The project investigates how modern machine learning (ML) and language-modeling techniques can classify proteins based solely on their amino acid sequences.

By treating protein sequences as biological text, we apply natural language processing (NLP), recurrent neural networks (LSTMs), and pre-trained large language models (LLMs, e.g., ESM-2) to analyze patterns within primary structure and predict each proteinâ€™s functional class.

The project emphasizes:

Lightweight, GPU-friendly workflows

Methods that balance computational efficiency with biological relevance

Practical comparisons between NLP, LSTM, and LLM-based approaches

Exploratory data analysis (EDA) of protein sequences from the Protein Data Bank (PDB)

ğŸ“‚ Repository Structure
repo/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ protein_classification.ipynb
â”‚
â”œâ”€â”€ data/                # (not included in repo; see instructions below)
â”‚   â”œâ”€â”€ metadata.csv
â”‚   â””â”€â”€ sequences.csv
â”‚
â”œâ”€â”€ figures/             # Auto-generated EDA and model evaluation plots
â”‚
â”œâ”€â”€ models/              # Saved model weights / Optuna results (optional)
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ“¦ Dataset

Data originate from:

Kaggle â€“ Protein Data Set
(originally sourced from the RCSB Protein Data Bank)

Two files are used:

metadata â€” experimental and structural metadata

sequences â€” amino acid sequences for all chains

ğŸ” Key preprocessing steps

Merge metadata and sequences on structureId

Filter for proteins only (exclude DNA/RNA)

Drop missing sequences or labels

Clean sequences to the 20 standard amino acids

Filter by length 20â€“1024 residues

Concatenate multi-chain sequences

Select the top 20 protein classes by representation

Split into train/validation/test sets (70/15/15)

ğŸš€ Project Pipelines

Three modeling pipelines were developed to compare ML approaches:

ğŸ§µ Pipeline 1 â€” NLP + Tree-Based Models

Treats protein sequences as text:

3-mer tokenization

CountVectorizer

SMOTE for class imbalance

Dimensionality reduction (SVD)

Baseline model search with LazyClassifier

Hyperparameter tuning using Optuna

Best model: Tuned Random Forest
Accuracy: ~69.7%

Strengths: extremely lightweight, fast to train
Limitations: weak for long-range dependencies

ğŸ” Pipeline 2 â€” LSTM Sequence Model

A BiLSTM built in Keras/TensorFlow:

Tokenized and padded sequences

Bidirectional LSTM

Class weighting for imbalanced classes

Trained for 50â€“100 epochs

Best validation accuracy: ~78.2%

Strengths: captures long-range sequence patterns
Limitations: training speed bottleneck on CPU hardware

ğŸ§  Pipeline 3 â€” LLM Embeddings (ESM-2)

Uses pre-trained transformer embeddings:

Model: esm2_t6_8M_UR50D (Meta AI)

Extracted high-dimensional embeddings per sequence

Trained tree-based and shallow neural classifiers on embeddings

UMAP visualization demonstrated biologically meaningful clusters

Strengths: highest biological fidelity with minimal training
Limitations: generating full embeddings is computationally expensive

ğŸ“Š Exploratory Data Analysis

The notebook includes:

Sequence length distributions

Protein class frequency

Amino acid composition and biochemical grouping

PCA and UMAP visualizations

Secondary structure propensity logo plots (Logomaker)

These analyses highlight the complexity of functional classification and motivate the use of advanced sequence models.

ğŸ› ï¸ Installation

Python version: 3.10+ recommended

git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
pip install -r requirements.txt

ğŸ“ Data Download

Due to size restrictions, data files are not stored in the repository.

Download from Kaggle:

https://www.kaggle.com/datasets/shahir/protein-data-set

Place the two CSVs in:

data/metadata.csv
data/sequences.csv

â–¶ï¸ Usage

Run the Jupyter notebook:

jupyter notebook notebooks/protein_classification.ipynb


The notebook includes:

Data preprocessing

All three modeling pipelines

EDA visualizations

Hyperparameter tuning

Performance comparisons

ğŸ”¬ Results Summary
Pipeline	Method	Validation Accuracy	Notes
1	NLP + Random Forest	~69.7%	Lightweight baseline
2	BiLSTM	~78.2%	Captures sequence relationships
3	ESM-2 Embeddings	TBD (in progress)	Best biological clustering
ğŸ“˜ Discussion

This project shows how treating protein sequences as language unlocks powerful machine-learning workflows. While classic NLP and LSTMs provide solid baselines, pre-trained LLM embeddings demonstrate the most promise, especially for complex biological classification tasks.

Future work will expand embedding generation, investigate fine-tuning transformer models, and explore generative approaches for intelligent drug design.

ğŸ“ Citation

If you use this repository in your work, please cite:

Machine Learning Classification of Structural Protein Sequences for Drug Discovery
Paul London & Ernest Bonat, Ph.D. (2025)

ğŸ“§ Contact

For questions, collaboration, or dataset access issues:

Paul London
ğŸ’¼ Bioinformatics & Data Scientist
ğŸ“« [Your email or GitHub profile link]
